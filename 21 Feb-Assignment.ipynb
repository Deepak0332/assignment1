{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e25733",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737fbb9-7ac5-4d7a-94c5-cf882098539e",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Web scraping is the process of extracting data from websites using automated tools or bots. It involves analyzing HTML or XML code of a web page and then programmatically extracting relevant data from it. \n",
    "\n",
    "Web scraping is used for various purposes and has become an essential tool for data extraction and analysis in many fields. Here are some common reasons why web scraping is used:\n",
    "\n",
    "1. Business Intelligence: Companies use web scraping to gather data on their competitors, market trends, and consumer behavior to gain insights and improve their business strategies.\n",
    "\n",
    "2. Research: Researchers use web scraping to collect data on various topics, such as social media trends, political opinions, and scientific research.\n",
    "\n",
    "3. E-commerce: E-commerce companies use web scraping to extract product information and pricing data from competitor websites to improve their pricing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d263c",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02caea04",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "There are several methods used for web scraping, including:\n",
    "\n",
    "1. Manual scraping: This method involves manually browsing a website and copying/pasting relevant data into a spreadsheet or other format.\n",
    "\n",
    "2. HTML parsing: This method involves analyzing the HTML code of a website and extracting relevant data using programming languages such as Python, PHP, or JavaScript.\n",
    "\n",
    "3. Web scraping tools: There are various web scraping tools available that can automate the process of extracting data from websites. Examples include Scrapy, Beautiful Soup, and Selenium.\n",
    "\n",
    "4. API scraping: Many websites offer APIs (Application Programming Interfaces) that can be used to access and extract data from their databases. API scraping involves using programming languages to interact with these APIs and extract the desired data.\n",
    "\n",
    "5. Screen scraping: This method involves capturing data from the screen using screen capture software. It is typically used for extracting data from non-web-based software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e03213",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2898ce",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Beautiful Soup is a Python library used for web scraping purposes. It is used to extract data from HTML and XML files. Beautiful Soup provides a simple way to navigate, search, and modify the parse tree of an HTML or XML document.\n",
    "\n",
    "Beautiful Soup is used because it simplifies the process of parsing HTML and XML documents. It can handle malformed markup and provides a consistent interface for navigating and searching the parse tree. Beautiful Soup can also be used to extract specific data from web pages, such as text, links, images, and other elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77041d09",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace00449",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Flask is a lightweight and flexible web framework that is used in this web scraping project because it provides a simple and easy-to-use interface for building web applications. Flask allows developers to quickly create web applications with minimal setup and configuration, making it an ideal choice for small to medium-sized projects like this one.\n",
    "\n",
    "In addition, Flask provides a number of useful features such as routing, templating, and request handling that make it easy to build dynamic web applications. It also integrates well with other Python libraries and tools commonly used in web scraping projects, such as Beautiful Soup and Requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e7cf9",
   "metadata": {},
   "source": [
    "## Q5) Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32238a27",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "**In this project we used AWS CodePipeline and AWS Elastic Beanstalk**\n",
    "\n",
    "**AWS CodePipeline:**\n",
    "AWS CodePipeline is a fully managed continuous delivery service that enables you to automate and streamline your software release process. It facilitates building, testing, and deploying your applications with a series of stages called pipelines. CodePipeline integrates with various AWS services and third-party tools, allowing you to create an end-to-end delivery workflow for your project. It supports source code repositories, build providers, testing services, and deployment targets, providing flexibility in configuring your pipeline based on your specific requirements.\n",
    "\n",
    "**AWS Elastic Beanstalk:**\n",
    "AWS Elastic Beanstalk is a platform as a service (PaaS) offering that simplifies deploying and managing applications. It abstracts away the underlying infrastructure, allowing you to focus on your application code. With Elastic Beanstalk, you can quickly deploy web applications and services without worrying about configuring and managing the underlying compute resources, load balancing, auto-scaling, and other infrastructure components. It supports multiple programming languages, frameworks, and environments, making it easier to run and scale your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6d0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
